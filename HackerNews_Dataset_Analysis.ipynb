{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing HackerNews Dataset to find the best time and category for creating a post.\n",
    "---\n",
    "## Introduction\n",
    "\n",
    "For all of you who do not know what HackerNews is,Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") receive votes and comments, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.You can find the original data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts)\n",
    "\n",
    "In this Project,We're specifically interested in posts with titles that begin with either `Ask HN` or `Show HN`. Users submit `Ask HN` posts to ask the Hacker News community a specific question. Likewise, users submit `Show HN` posts to show the Hacker News community a project, product, or just something interesting.  We are going to analyze a `downsampled dataset` of HackerNews posts to analyze the following things:\n",
    "* Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "**You can download the downsampled data from [here](https://dq-content.s3.amazonaws.com/356/hacker_news.csv)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'] \n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'] \n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'] \n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'] \n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the data file first\n",
    "from csv import reader\n",
    "file= open('hacker_news.csv')\n",
    "read=reader(file)\n",
    "hn=list(read)\n",
    "headers=hn[0]\n",
    "hn=hn[1:]\n",
    "print(headers,'\\n')\n",
    "for row in hn[:5]:\n",
    "    print(row,'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts\n",
    "Now, We are done with opening and reading our file, The next step is to identify the posts that start with `Ask HN` and `Show HN` because our analysis revolves around these posts. So we'll create `three` lists named `ask_posts`, `show_posts` and `other_posts`. The names are pretty self explanatory. Now to see the if the posts start with `Ask` or `Show` , We'll be using built-in string method `startswith` and `lower` string method. We'll see how in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ask_posts=[]\n",
    "show_posts=[]\n",
    "other_posts=[]\n",
    "for row in hn:\n",
    "    if (row[1].lower()).startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif (row[1].lower()).startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "print(len(ask_posts)) \n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "if len(ask_posts)+len(show_posts)+len(other_posts)==len(hn):\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above We see that all the posts have been covered because our condition returned **`True`**, We used `string.lower()` method to make sure if somebody wrote `ask HN` or `Ask Hn` instead of `Ask HN` in their post title, it will still be added to `ask_posts` and not `other_posts`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Calculating the Average Number of Comments for Ask HN and Show HN Posts\n",
    "\n",
    "Now, We'll calculate the `average` number of comments received in `ask_posts` and the `average` number of comments received in `show_posts`, so we can determine what kind of posts get better engagement and viewership.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Comments in \"Ask Hn:\" posts: 14.038417431192661\n",
      "Average Comments in \"Show Hn:\" posts: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments=0\n",
    "total_show_comments=0\n",
    "for row in ask_posts:\n",
    "    total_ask_comments+=int(row[4])\n",
    "for row in show_posts:\n",
    "    total_show_comments+=int(row[4])\n",
    "avg_ask_comments=total_ask_comments/len(ask_posts)\n",
    "avg_show_comments=total_show_comments/len(show_posts)\n",
    "print('Average Comments in \"Ask Hn:\" posts:',avg_ask_comments)\n",
    "print('Average Comments in \"Show Hn:\" posts:',avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, On average `Ask Hn:` posts have more comments than `Show HN:` posts, where `Ask` posts average at 14 comments and `Show` posts average at 10 comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Number of Ask Posts and Comments by Hour Created\n",
    "---\n",
    "Now, We know that `Ask` posts generate more viewership and engagement, We'll continue with only `Ask` posts and leave the `show` posts behind. Now, We'll take a look at the posts and see the time the posts were created. We are going to count the posts created by `hour` and then analyse at which hour of the day max posts were created and which hour had maximum comments. For this step, we will be using the `datetime` module, specifically `strptime` method and `strftime` method in `datetime` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'09': 251,\n",
       " '13': 1253,\n",
       " '10': 793,\n",
       " '14': 1416,\n",
       " '16': 1814,\n",
       " '23': 543,\n",
       " '12': 687,\n",
       " '17': 1146,\n",
       " '15': 4477,\n",
       " '21': 1745,\n",
       " '20': 1722,\n",
       " '02': 1381,\n",
       " '18': 1439,\n",
       " '03': 421,\n",
       " '05': 464,\n",
       " '19': 1188,\n",
       " '01': 683,\n",
       " '22': 479,\n",
       " '08': 492,\n",
       " '04': 337,\n",
       " '00': 447,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '11': 641}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt #we are creating an alias 'dt' for datetime module so it is easier to write\n",
    "counts_by_hour={}\n",
    "comments_by_hour={}\n",
    "result_list=[]\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6],int(row[4])])\n",
    "for item in result_list:\n",
    "    date=dt.datetime.strptime(item[0],'%m/%d/%Y %H:%M')\n",
    "    hour=date.strftime('%H')\n",
    "    comments=item[1]\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour]+=1\n",
    "        comments_by_hour[hour]+=comments\n",
    "    else:\n",
    "        counts_by_hour[hour]=1\n",
    "        comments_by_hour[hour]=comments\n",
    "comments_by_hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN Posts by Hour\n",
    "Now We have two dictionaries, One representing the number of posts that were created on a particular hour throughout the time frame of the dataset, and the other dictionary representing the number of total comments that were posted on a particular hour each day, throughout the time frame of the dataset. Now that we have this information, We will make an average of number of comments on `Ask HN` posts by hour. That will give us an idea of when the community of HackerNews is most active and what is the best time to create a post. We will create a `list of lists` that will contain the **hour** of the post created and **average comments** by hour in the given order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour=[]\n",
    "for hour in comments_by_hour:\n",
    "    comments=comments_by_hour[hour]\n",
    "    count=counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour,comments/count])\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Printing Values from a List of Lists\n",
    "We are almost DONE!, However the list `avg_by_hour` that we see above, It doesn't really look neat and easy to analyze and that is because it's not sorted by the highest count of comments. This list is not that big so it is somewhat easy to go through it but if the list was really big, we wouldn't be able to find much without sorting. Let's also get the comments to two decimal places to make it look neat and easy to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments.\n",
      "\n",
      "At 15:00: 38.59 average comments per post.\n",
      "At 02:00: 23.81 average comments per post.\n",
      "At 20:00: 21.52 average comments per post.\n",
      "At 16:00: 16.80 average comments per post.\n",
      "At 21:00: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour=[]\n",
    "for item in avg_by_hour:\n",
    "    swap_avg_by_hour.append([item[1],item[0]]) #swapped because the sorted\n",
    "sorted_swap=sorted(swap_avg_by_hour,reverse=True)#function sorts based on \n",
    "print('Top 5 Hours for Ask Posts Comments.\\n')#first value\n",
    "for item in sorted_swap[:5]:\n",
    "    template='At {}: {:.2f} average comments per post.'\n",
    "    time=dt.datetime.strptime(item[1],'%H')\n",
    "    time=time.strftime('%H:%S')\n",
    "    print(template.format(time,item[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "So, There we go, The top 5 hours to make a post for the most interaction. But this is for EST timezone, as mentioned in the [documentation](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts) of the dataset. Since, my timezone is the same, I didn't need to, But you might! We found that Ask Posts made between the time 1500-1600 EST hours(3:00 pm-4:00 pm EST) received more comments. Keep in mind that we did not include the posts with no title, so essentially this analysis is only for the Ask posts.\n",
    "\n",
    "***A.G.***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
